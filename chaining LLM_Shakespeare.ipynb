{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90807843",
   "metadata": {},
   "source": [
    "## Chaining LLM with PCA to visualize the Shakespeare text's characters and traits through correspondence analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6282db4",
   "metadata": {},
   "source": [
    "### taught process:\n",
    "\n",
    "## steps:\n",
    "1- **choose a dataset:** Shakespeare: I take a look at data and investigate the text \n",
    "\n",
    "2- **preprocess and clean:** remove extra characters like escape chars \n",
    "    - there are *** that separate header and footers, so I use this indicator to throw away unncessary text\n",
    "    -  removed extra spaces\n",
    "    \n",
    "3- **LLM request:** NER: assign score to each trait of that character\n",
    "    \n",
    "    \n",
    "4- **LLM request:** NER: assign score to each trait of that character\n",
    "    - I run the for loop to have an API call and get response and investigate it.\n",
    "    - After each investigation I add some more instructions to teh prompt and modify it. to get better result.\n",
    "    - I printed response methods step by step until I end up with response.json['choices'][0]['message']['content']\n",
    "    - converted str to dict\n",
    "    \n",
    "    \n",
    "5- **PCA:** create a plot of principle component analysis using the 2 top components (on a 2-d plane)\n",
    "    - I played around with the traits and add and remove to see how it works.\n",
    "\n",
    "\n",
    "I want to use LLM to get the corpus and extract relevant sections to a character. For example outputs the text related to Hamlet. I will tell in the prompt that I'll use this input later.\n",
    "Next I'll use the output of this LLM as an input to the next LLM. So in LLM 2, I want the agent to get the relevant info of a character and considering a list of traits it outputs a score for each of the traits. for examle like this:\n",
    "\n",
    "[\"indecisiveness\":10, \"ambitious\":7, \"innocence\":1]\n",
    "\n",
    "Then I feed these characters together with their corresponding trait score into a PCA to map them all into a Cartesian plane and compare and analyze\n",
    "\n",
    "Why I choose 4 characters: I searched to find the top famous characters in the Shakespeare text. For simplicity I keep it as 4 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c87fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sacremoses==0.0.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d815dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install chromadb==0.4.21 tiktoken==0.5.2 sqlalchemy==2.0.15 faiss-cpu==1.7.4 langchain==0.0.352 mlflow==2.9.2 databricks-genai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a27eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain-community "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8546cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4979b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh\n",
    "export DATABRICKS_TOKEN=<My_token>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test llm\n",
    "from langchain.chat_models import ChatDatabricks\n",
    "from langchain.embeddings import DatabricksEmbeddings\n",
    "\n",
    "embeddings = DatabricksEmbeddings(endpoint=\"databricks-bge-large-en\") # Use to generate embeddings\n",
    "llm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-70b-instruct\", temperature=0.1) # use to query models like Llama2-70b\n",
    "\n",
    "query = \"Why is the difference between Cat and Dog?\"\n",
    "\n",
    "embedding = embeddings.embed_query(query)\n",
    "response = llm.invoke(query)\n",
    "\n",
    "print(embedding[:5])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181cbc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "from langchain.document_loaders import GutenbergLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "full_text = GutenbergLoader(\"https://www.gutenberg.org/cache/epub/100/pg100.txt\").load() # All of Shakespeare 5967830\n",
    "\n",
    "print (f\"{full_text[0].page_content} characters in the doc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee25963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up\n",
    "content = full_text[0].page_content.split('***')\n",
    "cleaned_corpus = content[2].replace(\"  \", \" \")#.replace(\"\\n\", \" \")\n",
    "# cleaned_corpus is what we need in our next step\n",
    "print(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb603314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract relevant info\n",
    "def extract_relevant_info(text, character):\n",
    "  paragraphs = text.split(\".\")# split the whole text into paragraphs\n",
    "  relevant_paragraphs = [paragraph for paragraph in paragraphs if character in paragraph] \n",
    "  # if a character is found in a paragraph then keep that paragraph as a relevant paragraph\n",
    "  return \" \".join(relevant_paragraphs)[0:3500] # to avoid token bloat (4096) I cut down the size of the text to 3500\n",
    "\n",
    "print(len(extract_relevant_info(cleaned_corpus, \"Macbeth\")))\n",
    "characters = [\"Hamlet\", \"Romeo\", \"Juliet\", \"Othello\", \"Macbeth\"] # len =[11640, 7152, 6026, 8149]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c371c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract scale 0 to 10 using LLM\n",
    "from databricks_genai_inference import ChatCompletion\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "traits = [\"indecisiveness\", \"innocence\", \"jealous\", \"ambitious\", \"beauty\"]\n",
    "df = pd.DataFrame(columns=['Character'] + traits)\n",
    "# loop over the characters and for each Character create a list of traits with their scores\n",
    "for char in characters:\n",
    "  prompt = f\"\"\"\n",
    "           consider character {char}, from the collected work of Shakespeare, and provide scores on a scale of 0 to 10 \n",
    "           for the following personality traits:\n",
    "           \"indecisiveness\", \"innocence\", \"jealous\", \"ambitious\", \"beauty\".\n",
    "           Give scores based on the {char}'s dialogs, actions, and descriptions. Use only the content provided to you and do not make up things.\n",
    "           Return only the JSON output, without any additional explanatory text. Pay close attention to the dialogs, actions, and descriptions and do your best in assigning scores to each trait. If there is no implicit nor explicit mention of a specific trait for a character, and you cannot infer it, then simply consider 0 for that.\n",
    "           Try to not assign similar scores for the same trait to different characters. I want to feed your output into a principle component analysis and map all traits and characters into a single Cartesian plane. So assign the scores in a way to avoid messy diagram as much as possible.\n",
    "           Here is an example of desired output:\n",
    "           {{\n",
    "             \"{char}\":{{\n",
    "             \"indecisiveness\": 7,\n",
    "             \"innocence\": 9, \n",
    "             \"jealous\": 1, \n",
    "             \"ambitious\": 5, \n",
    "             \"beauty\":2\n",
    "           }}\n",
    "           }}\n",
    "           \"\"\"\n",
    "  response = ChatCompletion.create(\n",
    "            model=\"databricks-meta-llama-3-70b-instruct\", #DBx serving endpoint\n",
    "            messages = [           \n",
    "                        {\"role\": \"system\", \"content\": prompt},\n",
    "                        {\"role\": \"user\", \"content\": extract_relevant_info(cleaned_corpus, char)}],\n",
    "            temperature = 0.2,\n",
    "            max_tokens=4096\n",
    "            )\n",
    "  #print(response.json['choices'][0]['message']['content'])# type: string\n",
    "  print(\"<<<<<<<<<<<<<<<>>>>>>>>>>>>\")\n",
    "  # convert string to dictionary to be able to work on it \n",
    "  response_dict = json.loads(response.json['choices'][0]['message']['content'])\n",
    "  #print(response_dict, type(response_dict))\n",
    "  scores = {trait: response_dict[char][trait] for trait in traits}\n",
    "  scores['Character'] = char\n",
    "  df = df.append(scores, ignore_index=True) \n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ebce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(response.json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8652290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA. Principal component Analysis \n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.decomposition import PCA  \n",
    "\n",
    "df.set_index('Character', inplace=True) # \n",
    "pca = PCA(n_components = 2)\n",
    "pca_result = pca.fit_transform(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0194ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Visualization\n",
    "\n",
    "plt.figure(figsize=(12, 8)) \n",
    "# plot characters\n",
    "for i, character in enumerate(df.index):\n",
    "  plt.scatter(pca_result[i, 0], pca_result[i, 1], color='green', s=100, edgecolors='black')\n",
    "  plt.text(pca_result[i, 0], pca_result[i, 1], character)\n",
    "# plot traits\n",
    "for i, trait in enumerate(df.columns):\n",
    "  plt.scatter(pca.components_[0, i], pca.components_[1, i], color='cyan', marker='^')\n",
    "  plt.text(pca.components_[0, i], pca.components_[1, i], trait, fontsize=9, ha='left') \n",
    "  # ha stands for \"horizontal alignment.\" It controls the alignment of the text relative to the coordinates provided.\n",
    "plt.grid(True)\n",
    "plt.title(\"PCA of Shakespeare's charactes and traits\")\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0, color='black', linewidth=0.5)\n",
    "plt.show()\n",
    "#  [\"indecisiveness\", \"innocence\", \"jealous\", \"ambitious\", \"beauty\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76ef0c0b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb62b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07372991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
